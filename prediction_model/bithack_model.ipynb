{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOdH_tRbj459"
      },
      "outputs": [],
      "source": [
        "!pip install pandas\n",
        "!pip install openpyxl\n",
        "!pip install joblib\n",
        "!pip install requests\n",
        "!pip install geojson\n",
        "!pip install sklearn\n",
        "!pip install numpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import unicodedata\n",
        "import requests\n",
        "import geojson\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
      ],
      "metadata": {
        "id": "WDJvPaRTkGyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STAREZ data\n",
        "\n",
        "starez_excel_file = '/content/Starez.xlsx'\n",
        "\n",
        "# Load the Excel file\n",
        "df_starez_data = pd.read_excel(starez_excel_file, sheet_name='Data', engine='openpyxl', header=0)\n",
        "df_starez_ciselnik = pd.read_excel(starez_excel_file, sheet_name='Číselník', engine='openpyxl', header=None, skiprows=1)"
      ],
      "metadata": {
        "id": "DaROk4Ndmavt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_starez_data.rename(columns={df_starez_data.columns[0]: 'Zkratka'}, inplace=True)\n",
        "df_starez_data.head()"
      ],
      "metadata": {
        "id": "6GR9DjobpQKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# odstraneni duplikatu\n",
        "# Najdi index řádku, kde je ve sloupci 'Zkratka' hodnota 'Celkový součet'\n",
        "#index_to_drop_from = df_starez_data[df_starez_data['Zkratka'] == 'Celkový součet'].index[0]\n",
        "\n",
        "# Dropni všechny řádky od tohoto indexu (včetně) dolů a přepiš původní DataFrame\n",
        "#df_starez_data = df_starez_data[:index_to_drop_from]\n",
        "\n",
        "# Zobraz prvních pár řádků vyčištěného DataFrame\n",
        "#df_starez_data.head()"
      ],
      "metadata": {
        "id": "_dMOkLJd5ZWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_starez_data.shape[0]"
      ],
      "metadata": {
        "id": "oSB43SpO_7Ar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_starez_data = df_starez_data[df_starez_data['Zkratka'] != 'ESHOP']"
      ],
      "metadata": {
        "id": "A8Ubixmz-d8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_starez_data.shape[0]"
      ],
      "metadata": {
        "id": "E2Zu5Vk1AOG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_starez_ciselnik.columns = ['Identifikator', 'Zkratka', 'Název sportoviště']\n",
        "df_starez_ciselnik"
      ],
      "metadata": {
        "id": "7tQseMBEp2cS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Odstraníme řádek, kde je ve sloupci 'Zkratka' hodnota 'ESHOP'\n",
        "df_starez_ciselnik = df_starez_ciselnik[df_starez_ciselnik['Zkratka'] != 'ESHOP']\n",
        "\n",
        "# Zobrazíme výsledný DataFrame\n",
        "df_starez_ciselnik"
      ],
      "metadata": {
        "id": "tfCNSbli9liv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Proveď sloučení na základě sloupce 'Zkratka'\n",
        "df_starez_merged = pd.merge(df_starez_data, df_starez_ciselnik[['Zkratka', 'Název sportoviště']], on='Zkratka', how='left')\n",
        "\n",
        "# Nahradíš první sloupec v Data novým názvem sportoviště (třetí sloupec z Číselníku)\n",
        "df_starez_merged['Zkratka'] = df_starez_merged['Název sportoviště']\n",
        "\n",
        "# Odstraníš pomocný sloupec 'Název sportoviště'\n",
        "df_starez_merged.drop(columns=['Název sportoviště'], inplace=True)\n",
        "\n",
        "# Prejmenovani mesice\n",
        "df_starez_merged.rename(columns={'Měsíc ': 'Měsíc'}, inplace=True)\n",
        "\n",
        "# Zobraz první řádky výsledku\n",
        "df_starez_merged.head()"
      ],
      "metadata": {
        "id": "t1WQO4uyphEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# WEATHER DATA HISTORY\n",
        "\n",
        "# Load the \"Data\" sheet from the Excel file\n",
        "#df_weather_historical = pd.read_excel('/content/B2BTUR01.xlsx', sheet_name='teplota průměrná', engine='openpyxl', header=3)\n",
        "df_weather_historical_dict = pd.read_excel('/content/B2BTUR01.xlsx', sheet_name=None, engine='openpyxl', header=3)\n",
        "\n",
        "\n",
        "# Function to remove diacritics from a string\n",
        "def remove_diacritics(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Rename the specific sheet in the DataFrame\n",
        "if 'rychlost větru ' in df_weather_historical_dict:\n",
        "    df_weather_historical_dict['rychlost větru'] = df_weather_historical_dict.pop('rychlost větru ')\n",
        "\n",
        "# List of sheets to merge\n",
        "sheets_to_merge = [\n",
        "    'teplota průměrná', 'teplota maximální', 'teplota minimální',\n",
        "    'rychlost větru', 'tlak vzduchu', 'vlhkost vzduchu',\n",
        "    'úhrn srážek', 'celková výška sněhu', 'sluneční svit'\n",
        "]\n",
        "\n",
        "# List to store melted DataFrames\n",
        "melted_dfs = []\n",
        "\n",
        "# Process each sheet\n",
        "for sheet_name in sheets_to_merge:\n",
        "    df = df_weather_historical_dict[sheet_name]\n",
        "    # Melt the DataFrame\n",
        "    melted_df = df.melt(id_vars=['rok', 'měsíc'],\n",
        "                        value_vars=[str(i) + '.' for i in range(1, 32)],  # Add '.' to match the columns\n",
        "                        var_name='day', value_name='value')\n",
        "\n",
        "    # Rename the 'value' column to include the sheet name and remove diacritics\n",
        "    melted_df.rename(columns={'value': f'{remove_diacritics(sheet_name)}_value'}, inplace=True)\n",
        "\n",
        "    # Convert 'day' to numeric for merging purposes\n",
        "    melted_df['day'] = pd.to_numeric(melted_df['day'])\n",
        "\n",
        "    # Add the melted DataFrame to the list\n",
        "    melted_dfs.append(melted_df)\n",
        "\n",
        "# Merge all melted DataFrames\n",
        "merged_df = melted_dfs[0]\n",
        "for df in melted_dfs[1:]:\n",
        "    merged_df = pd.merge(merged_df, df, on=['rok', 'měsíc', 'day'], how='outer')\n",
        "\n",
        "# Change type for day\n",
        "merged_df['day'] = merged_df['day'].astype('Int64')\n",
        "\n",
        "# Display the final merged DataFrame\n",
        "merged_df.head()\n",
        "\n",
        "\n",
        "# Display the first few rows\n",
        "#df_weather_historical.head()"
      ],
      "metadata": {
        "id": "8weQhf1gmqWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.rename(columns={'rok': 'Rok', 'měsíc': 'Měsíc', 'day': 'Den'}, inplace=True)\n",
        "merged_df.head()"
      ],
      "metadata": {
        "id": "8csVr1swuEkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "X47oFW5Hvo1d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_starez_merged[['Rok', 'Měsíc', 'Den', 'Veřejnost', 'Hodina', 'Abonenti', 'Celkem']] = df_starez_merged[['Rok', 'Měsíc', 'Den', 'Veřejnost', 'Hodina', 'Abonenti', 'Celkem']].astype(\"Int64\")\n",
        "\n",
        "# Provedeme sloučení na základě Rok, Měsíc a Den\n",
        "df_train = pd.merge(df_starez_merged, merged_df, on=['Rok', 'Měsíc', 'Den'], how='left')\n",
        "\n",
        "# Identify columns that end with 'value'\n",
        "value_columns = df_train.filter(regex='value$').columns\n",
        "\n",
        "# Round those columns to 1 decimal place\n",
        "df_train[value_columns] = df_train[value_columns].round(1)\n",
        "\n",
        "\n",
        "# Display the merged dataframe\n",
        "df_train.head()"
      ],
      "metadata": {
        "id": "TbPGsrc2swlo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DATA PREPROCESSING"
      ],
      "metadata": {
        "id": "rh9fuE3B250D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.info()"
      ],
      "metadata": {
        "id": "b6AVLl2iwGJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = df_train[df_train['Rok'] <= 2022]\n",
        "df_train.head()"
      ],
      "metadata": {
        "id": "D3EEqbJEwbxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train[['Veřejnost', 'Abonenti']] = df_train[['Veřejnost', 'Abonenti']].fillna(0).astype('Int64')\n",
        "df_train.head()"
      ],
      "metadata": {
        "id": "_7nMz48ywgZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['Celkem'] = df_train['Veřejnost'] + df_train['Abonenti']\n",
        "df_train.head()"
      ],
      "metadata": {
        "id": "KBPE1Pbw5KBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count of missing values in each column\n",
        "missing_values = df_train.isnull().sum()\n",
        "print(missing_values[missing_values > 0])  # Display only columns with missing values"
      ],
      "metadata": {
        "id": "LI9LNMUZ5eLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Spočítáme průměrnou hodnotu sloupce 'slunecni svit', přičemž ignorujeme NaN hodnoty\n",
        "mean_value = df_train['slunecni svit_value'].mean()\n",
        "\n",
        "# Nahradíme chybějící hodnoty (NaN) průměrnou hodnotou\n",
        "df_train['slunecni svit_value'] = df_train['slunecni svit_value'].fillna(mean_value)\n",
        "\n",
        "# Zobrazíme první řádky, abychom ověřili výsledek\n",
        "df_train.head()"
      ],
      "metadata": {
        "id": "OG1emjaT6TSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count of missing values in each column\n",
        "missing_values = df_train.isnull().sum()\n",
        "print(missing_values[missing_values > 0])  # Display only columns with missing values"
      ],
      "metadata": {
        "id": "QYjP_1bh7joQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.info()"
      ],
      "metadata": {
        "id": "_fOuRYC8-JrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Odstraníme řádky, které mají NaN ve sloupci 'Zkratka'\n",
        "df_train = df_train.dropna(subset=['Zkratka'])\n",
        "\n",
        "mean_value = df_train['rychlost vetru_value'].mean()\n",
        "# Use .loc to avoid the SettingWithCopyWarning\n",
        "df_train.loc[:, 'rychlost vetru_value'] = df_train['rychlost vetru_value'].fillna(mean_value)"
      ],
      "metadata": {
        "id": "mHRfWtx5-MaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['day_of_week'] = pd.to_datetime(df_train[['Rok', 'Měsíc', 'Den']].rename(columns={'Rok': 'year', 'Měsíc': 'month', 'Den': 'day'})).dt.dayofweek\n",
        "# Assuming df is your DataFrame\n",
        "df_train['mean_abonenti'] = df_train.groupby(['Měsíc', 'Den'])['Abonenti'].transform('mean')\n",
        "df_train['mean_verejnost'] = df_train.groupby(['Měsíc', 'Den'])['Veřejnost'].transform('mean')"
      ],
      "metadata": {
        "id": "FKZDqFbvxvQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Calculate mean values for the historical features\n",
        "mean_historical_values = df_train.groupby(['Měsíc', 'Den', 'Hodina'])[\n",
        "    ['rychlost vetru_value',\n",
        "     'tlak vzduchu_value',\n",
        "     'vlhkost vzduchu_value',\n",
        "     'uhrn srazek_value']].transform('mean')\n",
        "\n",
        "# Step 2: Add the mean values as new columns to df_train\n",
        "df_train[['mean_rychlost_vetru',\n",
        "           'mean_tlak_vzduchu',\n",
        "           'mean_vlhkost_vzduchu',\n",
        "           'mean_uhrn_srazek']] = mean_historical_values\n",
        "\n",
        "# Step 3: Ensure your date and hour columns are in the correct format\n",
        "df_train['Date'] = pd.to_datetime(df_train[['Rok', 'Měsíc', 'Den']].rename(columns={'Rok': 'year', 'Měsíc': 'month', 'Den': 'day'}))\n",
        "\n",
        "# Step 4: Group by Date and Hour, and calculate mean for the specified columns\n",
        "mean_values = df_train.groupby(['Date', 'Hodina'])[['teplota maximalni_value',\n",
        "                                                      'teplota minimalni_value',\n",
        "                                                      'Abonenti',\n",
        "                                                      'Veřejnost',\n",
        "                                                      'celkova vyska snehu_value',\n",
        "                                                      'slunecni svit_value',\n",
        "                                                      'mean_rychlost_vetru',\n",
        "                                                      'mean_tlak_vzduchu',\n",
        "                                                      'mean_vlhkost_vzduchu',\n",
        "                                                      'mean_uhrn_srazek']].mean().reset_index()\n",
        "\n",
        "# Rename columns for clarity (optional)\n",
        "mean_values.columns = ['Date', 'Hodina', 'Mean_Teplota_Max', 'Mean_Teplota_Min',\n",
        "                       'Mean_Abonenti', 'Mean_Verejnost',\n",
        "                       'Mean_Celkova_Vyska_Snehu', 'Mean_Slunecni_Svit',\n",
        "                       'Mean_Rychlost_Vetru', 'Mean_Tlak_Vzduchu',\n",
        "                       'Mean_Vlhkost_Vzduchu', 'Mean_Uhrn_Srazek']\n",
        "\n",
        "# Step 5: Save the result to a CSV file\n",
        "mean_values.to_csv('mean_values_hourly.csv', index=False)\n",
        "\n",
        "# Display the first few rows of the mean values DataFrame\n",
        "mean_values.head()"
      ],
      "metadata": {
        "id": "V3BDRAuzopl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 'rychlost vetru_value', 'tlak vzduchu_value', 'vlhkost vzduchu_value', 'uhrn srazek_value'\n",
        "# Calculate mean values for the historical features\n",
        "\n",
        "# DROPPING VALUES\n",
        "# Remove not needed features\n",
        "df_train = df_train.drop(columns=['Rok', 'Abonenti', 'Veřejnost',\n",
        "                                  'teplota maximalni_value', 'teplota minimalni_value', 'celkova vyska snehu_value', 'slunecni svit_value',\n",
        "                                  'rychlost vetru_value', 'tlak vzduchu_value', 'vlhkost vzduchu_value', 'uhrn srazek_value',\n",
        "                                  'mean_vlhkost_vzduchu'])\n",
        "\n",
        "# Zobrazíme první řádky výsledného DataFrame\n",
        "df_train.head()"
      ],
      "metadata": {
        "id": "O27aNlrkoius"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count of missing values in each column\n",
        "missing_values = df_train.isnull().sum()\n",
        "print(missing_values[missing_values > 0])  # Display only columns with missing values"
      ],
      "metadata": {
        "id": "x7kXnsNYHFn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Assuming you have a DataFrame `df` with your data\n",
        "\n",
        "# Encode categorical variables (e.g., 'Zkratka')\n",
        "df_encoded = pd.get_dummies(df_train, columns=['Zkratka'], drop_first=True)\n",
        "# Assuming df_encoded is your DataFrame after one-hot encoding\n",
        "#print(\"New columns after one-hot encoding:\")\n",
        "#print(df_encoded.columns.tolist())\n",
        "\n",
        "# Define features and target variable\n",
        "X = df_encoded.drop(columns=['Celkem'])  # All columns except the target\n",
        "y = df_encoded['Celkem']  # Target variable\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the model\n",
        "#model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "\n",
        "# Mean Squared Error (MSE)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error (MSE):\", mse)\n",
        "\n",
        "# Root Mean Squared Error (RMSE)\n",
        "rmse = np.sqrt(mse)\n",
        "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
        "\n",
        "# Mean Absolute Error (MAE)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error (MAE):\", mae)\n",
        "\n",
        "# Mean Absolute Percentage Error (MAPE)\n",
        "mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
        "print(\"Mean Absolute Percentage Error (MAPE):\", mape)\n",
        "\n",
        "# R-squared (R²)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(\"R-squared (R²):\", r2)"
      ],
      "metadata": {
        "id": "gFY85gpxCZpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model\n",
        "joblib.dump(model, 'random_forest_model.pkl')\n",
        "\n",
        "# Load the model\n",
        "loaded_model = joblib.load('random_forest_model.pkl')\n",
        "\n",
        "# Make predictions with the loaded model\n",
        "predictions = loaded_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "print(\"Mean Squared Error:\", mse)"
      ],
      "metadata": {
        "id": "awkGd3jHIao_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set the size of the plot\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Create a heatmap\n",
        "\n",
        "# Select only numeric columns from df_train\n",
        "numeric_df = df_train.select_dtypes(include=['float64', 'int64'])\n",
        "\n",
        "# Calculate the correlation matrix\n",
        "correlation_matrix = numeric_df.corr()\n",
        "\n",
        "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', square=True, cbar=True)\n",
        "\n",
        "# Show the plot\n",
        "plt.title('Correlation Matrix')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "LPzfIgB87mtv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}